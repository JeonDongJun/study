{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 위키피디아 wikicorpus 이용하여 model만들기 ###\n",
    "# 2017-07-29\n",
    "\n",
    "# 참고사이트\n",
    "# http://blog.theeluwin.kr/post/146591096133/%ED%95%9C%EA%B5%AD%EC%96%B4-word2vec\n",
    "# http://textminingonline.com/training-word2vec-model-on-english-wikipedia-by-gensim\n",
    "\n",
    "import gensim\n",
    "from gensim.corpora import WikiCorpus, wikicorpus\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# 1. corpus(말뭉치)를 만든다\n",
    "# 한 문장이 한줄에 들어가야되는데 wikiCorpus를 이용하면 한 단락이 리스트에 들어간다. 잘모르겠다.. 그냥해도 나오긴 하는 듯\n",
    "\n",
    "wiki = WikiCorpus('kowiki-latest-pages-articles.xml.bz2', dictionary={}) # multistream 파일 안읽힘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. corpus를 txt파일로 저장한다. 시간 좀 걸림..\n",
    "\n",
    "import six\n",
    "\n",
    "# type(wiki)\n",
    "i = 1\n",
    "with open('result.txt', 'w', encoding='utf-8') as f:\n",
    "    for text in wiki.get_texts():\n",
    "        if six.PY3:\n",
    "            f.write(' '.join(text) + '\\n')\n",
    "        #   ###another method###\n",
    "        #    output.write(\n",
    "        #            space.join(map(lambda x:x.decode(\"utf-8\"), text)) + '\\n')\n",
    "        else:\n",
    "            f.write(space.join(text) + \"\\n\")\n",
    "        i = i + 1\n",
    "        if (i % 10000 == 0):\n",
    "            print(i)\n",
    "\n",
    "\n",
    "\n",
    "# dic 형식이나 matrix market 형식의 파일로 저장할 수 있다.\n",
    "# wiki.dictionary.save(\"wiki_dict.dict\")\n",
    "# MmCorpus.serialize(\"wiki_corpus.mm\", wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. 조사가 다 붙어있기 때문에 twitter 이용해서 떼준다.\n",
    "# 제임스/Noun 지미/Noun 카터/Noun... 이런식으로 / 여기도 시간 좀 걸림\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "\n",
    "twitter = Twitter()\n",
    "\n",
    "def flat(content):\n",
    "    return [\"{}/{}\".format(word, tag) for word, tag in twitter.pos(content)]\n",
    "\n",
    "k = open('result_k.txt','w')\n",
    "with open('result.txt','r') as f:\n",
    "    for line in f.readlines():\n",
    "        k.write(' '.join(flat(line)) + '\\n')\n",
    "\n",
    "k.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4. 학습시켜서 model 만들고 파일로 저장 \n",
    "# 설정 아직 다 모르겠음.. 빠르게 학습하기 위해서 설정했는데 공부 더 필요!! / 한시간정도 걸림\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "config = {\n",
    "    'min_count': 50,  # 등장 횟수가 5 이하인 단어는 무시\n",
    "    'size': 300,  # 300차원짜리 벡터스페이스에 embedding\n",
    "    'sg': 0,  # 0이면 CBOW, 1이면 skip-gram을 사용한다\n",
    "    'batch_words': 10000,  # 사전을 구축할때 한번에 읽을 단어 수\n",
    "    'iter': 10,  # 보통 딥러닝에서 말하는 epoch과 비슷한, 반복 횟수\n",
    "    'workers': multiprocessing.cpu_count(),\n",
    "}\n",
    "\n",
    "model = gensim.models.Word2Vec(LineSentence('result_k.txt'),**config) # LineSentence 이용하여 한 줄(리스트)씩 읽어올 수 있는 듯\n",
    "model.save('result_k.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('매킨토시/Noun', 0.48226165771484375),\n",
       " ('ios/Alpha', 0.46322768926620483),\n",
       " ('아이폰/Noun', 0.45036351680755615),\n",
       " ('버전/Noun', 0.44701114296913147),\n",
       " ('애플사/Noun', 0.4437728524208069)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. 완성! model로 맘대로 할 수 있다.\n",
    "# similar값이 높게 나오지 않는다....\n",
    "\n",
    "model = gensim.models.Word2Vec.load('result_k.model')\n",
    "\n",
    "model.most_similar(\"왕/Noun\")\n",
    "model.most_similar(positive=[\"형제/Noun\", \"여자/Noun\"], negative=[\"남자/Noun\"], topn=5)\n",
    "model.most_similar(positive=[\"갤럭시/Noun\",\"애플/Noun\"], negative=[\"삼성/Noun\"], topn=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
